---
title: "Developing a non-destructive metabarcoding protocol for detection of target insects in bulk trap catches"
author: "J. Batovska, A.M. Piper, I. Valenzuela, J.P. Cunningham & M.J. Blacket"
date: "2019/02/24"
output:
  html_document: default
  pdf_document: default
---


```{r setup, include=FALSE}

# Knitr global setup - change eval to true to run code

library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, fig.show = "hold", fig.keep = "all")
opts_knit$set(root.dir = 'C:/Users/ap0y/Dropbox/Work Projects/PHD/Metabarcoding/HemipteraMetabarcodingMS')
setwd('C:/Users/ap0y/Dropbox/Work Projects/PHD/Metabarcoding/HemipteraMetabarcodingMS')
opts_chunk$set(dev = 'png')

#load scripts from scripts folder
read_chunk('scripts/summary_func.R')
```

```{r summary_func, echo=FALSE}
##Load utility functions from scripts folder (defined in markdown header)

read_chunk('scripts/summary_func.R')
```

# Introduction 

This is the R based reproducible workflow that performed the metabarcoding analyses presented for the manuscript "Developing a non-destructive metabarcoding protocol for detection of target insects in bulk trap catches" by J. Batovska, A.M. Piper, I. Valenzuela, J.P. Cunningham & M.J. Blacket

The data that was analysed here includes 20 mock communities made up of Hemiptera, and 10 trap samples from a potato field. These were seperated over 3 runs on an illumina MiSeq

Run_1 - 15 pools of 100, 500, and 1000 insects
Run_2 - 5 pools of 250 insects, run in duplicate to compare combinatorial indexing and unique-dual indexing
Run_3 - 10 trap samples with varying numbers of insects

3 seperate genes were multiplexed in the one PCR amplification, and libraries were prepared from these

In this analysis pipeline, each MiSeq run was processed processed within a for-loop, so parameters are kept consistant


## Set up

Load all requried packages

```{r load packages, message=FALSE, eval = FALSE }
sapply(c("dada2", "phyloseq","ggplot","ips", "DECIPHER", "data.table", "ggplot", "tidyverse","Biostrings","ShortRead","scales","stringdist","patchwork", "psadd","ggpubr","seqinr", "viridis"), require, character.only = TRUE)

```

#Remove primers

DADA2 requires Non-biological nucleotides i.e. primers, adapters, linkers, etc to be removed. Prior to begining this workflow, samples were demultiplexed and illumina adapters were removed by the MiSeq software, however primer sequences still remain in the reads and must be removed prior to use with the DADA2 algorithm.

In this study there were 3 amplicons of different size generated in a multiplexed PCR. While COI should only contain the 5' primer, the 12S and 18S genes are length variable, and therefore may contain 3' primer sequences in addition to the 5'primer.

Therefore, for this workflow we will be using the Kmer based adapter trimming software BBDuk (Part of BBTools package https://jgi.doe.gov/data-and-tools/bbtools/) to trim the primers from our raw data files.

## Primers:            
```{code}
Name                    Illumina overhang adapter           Primer sequences
Sterno18S_F2_tail		ACACTCTTTCCCTACACGACGCTCTTCCGATCT		ATGCATGTCTCAGTGCAAG 
Sterno18S_R1_tail		GACTGGAGTTCAGACGTGTGCTCTTCCGATC 		TCGACAGTTGATAAGGCAGAC
Sterno12S_F2_tail		ACACTCTTTCCCTACACGACGCTCTTCCGATCT		CAYCTTGACYTAACAT
Sterno12S_R2_tail		GACTGGAGTTCAGACGTGTGCTCTTCCGATC			TAAAYYAGGATTAGATACCC
SternoCOI_F1_tail		ACACTCTTTCCCTACACGACGCTCTTCCGATCT		ATTGGWGGWTTYGGAAAYTG
SternoCOI_R1_tail		GACTGGAGTTCAGACGTGTGCTCTTCCGATC  		TATRAARTTRATWGCTCCTA
```

This script was handled externally in the linux terminal

```{bash bbduk trimming}
mkdir cleaned
ls | grep "R1_001.fastq.gz" | sort > test_ls_F
ls | grep "R2_001.fastq.gz" | sort > test_ls_R

let files=$(grep -c "fastq.gz" test_ls_F)

declare -i x
x=1


while [ $x -le $files ] 
	do

queryF=$(sed -n "${x}p" test_ls_F)
queryR=$(sed -n "${x}p" test_ls_R)

sample_nameF=$(echo $queryF | awk -F . '{ print $1}')
sample_nameR=$(echo $queryR | awk -F . '{ print $1}')

#Need to set location of bbduk - on basc it is contained in my root ~/bbmap/bbduk.sh

#Trim 3' primers from forward and reverse reads and any bases to the left
~/bbmap/bbduk.sh in=$sample_nameF.fastq.gz in2=$sample_nameR.fastq.gz out=$sample_nameF.temp.fastq.gz out2=$sample_nameR.temp.fastq.gz literal=ATTGGWGGWTTYGGAAAYTG,TATRAARTTRATWGCTCCTA,ATGCATGTCTCAGTGCAAG,TCGACAGTTGATAAGGCAGAC,CAYCTTGACYTAACAT,TAAAYYAGGATTAGATACCC copyundefined k=14 ordered=t rcomp=f ktrim=l tbo tpe;

#Trim 5' primers from forward and reverse reads and any bases to the right
~/bbmap/bbduk.sh in=$sample_nameF.temp.fastq.gz in2=$sample_nameR.temp.fastq.gz out=./cleaned/$sample_nameF.trimmed.fastq.gz out2=./cleaned/$sample_nameR.trimmed.fastq.gz literal=GGGTATCTAATCCTRRTTTA,ATGTTARGTCAAGRTG copyundefined k=14 ordered=t rcomp=f ktrim=r tbo tpe;
let x=x+1

done 2> bbduk_primer_trimming_stats.txt
rm *.temp.*

```

    
# DADA2 portion of workflow



## Error visualisation
We start by visualizing the quality profiles of the forward read and reverse reads for each run:

```{r pre filter plot, eval = FALSE, cache= TRUE}
runs <- dir("data/", pattern="run")

for (i in seq(along=runs)){
path <- paste0("data/",runs[i]) # CHANGE ME to the directory containing your demultiplexed forward-read fastq files

fastqFs <- sort(list.files(path, pattern="R1_001.trimmed.fastq.gz", full.names = TRUE))
fastqRs <- sort(list.files(path, pattern="R2_001.trimmed.fastq.gz", full.names = TRUE))
print(plotQualityProfile(fastqFs[1:4]) + ggtitle(paste0(runs[i]," Forward Reads")))
print(plotQualityProfile(fastqRs[1:4]) + ggtitle(paste0(runs[i]," Reverse Reads")))
}
```


## Filter and trim

The forward reads for the hemiptera metabarcoding data are of good quality, while The reverse reads are of slightly worse worse quality at the end, which is common in Illumina sequencing. Informed by these profiles, we will use the Truncate quality function (TruncQ=2) to cut the reads at any point the Q score crashes below 2.

```{r filter and trim}
##Note - for filtering stage, these parameters may not be optimal for each run or testset, use the previous plotting step to inform this
runs <- dir("data/", pattern="run")
filtered_out <- list()

for (i in seq(along=runs)){
  path <- paste0("data/",runs[i]) # CHANGE ME to the directory containing your demultiplexed forward-read fastq files
  filtpath <- file.path(path, "filtered") # Filtered forward files go into the path/filtered/ subdirectory
  
  fastqFs <- sort(list.files(path, pattern="R1_001.trimmed.fastq.gz"))
  fastqRs <- sort(list.files(path, pattern="R2_001.trimmed.fastq.gz"))
  
  if(length(fastqFs) != length(fastqRs)) stop(paste0("Forward and reverse files for ",runs[i]," do not match."))
  
  filtered_out[[i]] <- (filterAndTrim(fwd=file.path(path, fastqFs), filt=file.path(filtpath, fastqFs),
                                      rev=file.path(path, fastqRs), filt.rev=file.path(filtpath, fastqRs),
                                      maxEE=c(2,5), truncQ=2, maxN = 2, minLen = 100,
                                      rm.phix=TRUE, compress=TRUE, verbose=TRUE))
}
print(filtered_out)
```


## Post filtering error plotting

sanity check to see the effects of the filter and trim step

```{r Post filter plot, eval = FALSE, cache= TRUE}
runs <- dir("data/", pattern="run")

##Post filtering plotting
for (i in seq(along=runs)){
  path <- paste0("data/",runs[i]) # CHANGE ME to the directory containing your demultiplexed forward-read fastq files
  filtpath <- file.path(path, "filtered") # Filtered forward files go into the path/filtered/ subdirectory
  
  
  filtFs <- sort(list.files(filtpath, pattern="R1_001.trimmed.fastq.gz", full.names = TRUE))
  filtRs <- sort(list.files(filtpath, pattern="R2_001.trimmed.fastq.gz", full.names = TRUE))
  print(plotQualityProfile(filtFs[1:4]) + ggtitle(paste0(runs[i]," Forward Reads")))
  print(plotQualityProfile(filtRs[1:4]) + ggtitle(paste0(runs[i]," Reverse Reads")))
}

```

## Infer sequence variants

Every amplicon dataset has a different set of error rates and the DADA2 algorithm makes use of a parametric error model (err) to model this and infer real biological sequence variation from error. Following error model learning, all identical sequencing reads are dereplicated into into “Exact sequence variants” with a corresponding abundance equal to the number of reads with that unique sequence. The forward and reverse reads are then merged together by aligning the denoised forward reads with the reverse-complement of the corresponding reverse reads, and then constructing the merged “contig” sequences. Following this step, a sequence variant table is constructed and saved as an RDS file.

For this analysis we will use all the reads to estimate error rate, and plot the error model for each run as a sanity check

```{r Learn error rates }
runs <- dir("data/", pattern="run")
set.seed(100)

for (i in seq(along=runs)){
  path <- paste0("data/",runs[i]) # CHANGE ME to the directory containing your demultiplexed forward-read fastq files
  filtpath <- file.path(path, "filtered") # Filtered forward files go into the path/filtered/ subdirectory
  
  filtFs <- list.files(filtpath, pattern="R1_001.trimmed.fastq.gz", full.names = TRUE)
  filtRs <- list.files(filtpath, pattern="R2_001.trimmed.fastq.gz", full.names = TRUE)
  
  sample.names <- sapply(strsplit(basename(filtFs), "_"), `[`, 1) # Assumes filename = flowcell_samplename_XXX.fastq.gz
  sample.namesR <- sapply(strsplit(basename(filtRs), "_"), `[`, 1) # Assumes filename = flowcell_samplename_XXX.fastq.gz
  if(!identical(sample.names, sample.namesR)) stop("Forward and reverse files from run1 do not match.")
  names(filtFs) <- sample.names
  names(filtRs) <- sample.names
  
  # Learn error rates from samples
  # nread tells the function how many reads to use in error learning, this can be increased for more accuracy at the expense of runtime
  
  errF <- learnErrors(filtFs, multithread=TRUE)
  errR <- learnErrors(filtRs, multithread=TRUE)
  ##Print error plots to see how well the algorithm modelled the errors in the different runs
  print(plotErrors(errF, nominalQ=TRUE)+ ggtitle(paste0(runs[i]," Forward Reads")))
  print(plotErrors(errR, nominalQ=TRUE)+ ggtitle(paste0(runs[i]," Reverse Reads")))
  
  
  #Error inference and merger of reads
  mergers <- vector("list", length(sample.names))
  names(mergers) <- sample.names
  for(sam in sample.names) {
    cat("Processing:", sam, "\n")
    derepF <- derepFastq(filtFs[[sam]])
    ddF <- dada(derepF, err=errF, multithread=TRUE)
    
    derepR <- derepFastq(filtRs[[sam]])
    ddR <- dada(derepR, err=errR, multithread=TRUE)
    merger <- mergePairs(ddF, derepF, ddR, derepR) #, maxMismatch = 3
    mergers[[sam]] <- merger
  }
  

# Construct sequence table
seqtab<- makeSequenceTable(mergers)
saveRDS(seqtab, paste0(path,"/seqtab.rds")) # CHANGE ME to where you want sequence table saved
}
```


## Merge Runs, Remove Chimeras

Now that the sequence tables are created for each run, they need to be merged into a larger table representing the entire study. Following this, chimeric sequences are identified and removed using removeBimeraDenovo, and any identical sequences with the only difference being length variation are collapsed using collapseNoMismatch.

```{r merge runs and remove chimeras}
runs <- dir("data/", pattern="run")
stlist <- vector()

for (i in seq(along=runs)){
  path <- paste0("data/",runs[i]) # CHANGE ME to the directory containing your demultiplexed forward-read fastq files
  seqs <- list.files(path, pattern="seqtab.rds", full.names = TRUE)
  
  assign(paste("st", i, sep = ""),readRDS(seqs))
  stlist <- append(stlist, paste("st", i, sep = ""), after=length(seqs))
}

st.all <- mergeSequenceTables(st1, st2, st3)

st.all <- collapseNoMismatch(st.all, minOverlap = 20, orderBy = "abundance",
                                    vec = TRUE, verbose = TRUE)
seqtab.nochim <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE, verbose=TRUE)

print(paste(sum(seqtab.nochim)/sum(st.all),"of the abundance remaining after chimera removal"))

saveRDS(seqtab.nochim, "output/rds/seqtab_final.rds") # CHANGE ME to where you want sequence table saved

```

### Dada2 assign tax

```{r}

seqtab.nochim <- readRDS("output/rds/seqtab_final.rds")

# Assign Kingdom:Genus taxonomy using RDP classifier
tax <- assignTaxonomy(seqtab.nochim, "reference/merged_arthropoda_rdp_genus.fa", multithread=TRUE, minBoot=80, outputBootstraps=FALSE)
colnames(tax) <- c("Gene", "Phylum", "Class", "Order", "Family", "Genus")

##add species to taxtable using exact matching
tax_plus <- addSpecies(tax, "reference/merged_arthropoda_rdp_species.fa", allowMultiple=TRUE)

##Add SP. to species rank for those with only a genus rank assignmnet
for(col in seq(7,ncol(tax_plus))) { 
  propagate <- is.na(tax_plus[,col]) & !is.na(tax_plus[,col-1])
  tax_plus[propagate,col:ncol(tax_plus)] <-  "spp."
}

##join genus and species name in species rank column
sptrue <- !is.na(tax_plus[,7])
tax_plus[sptrue,7] <- paste(tax_plus[sptrue,6],tax_plus[sptrue,7], sep=" ")

#Check Output
taxa.print <- tax_plus # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)

# Write taxonomy table to disk
saveRDS(tax_plus, "output/rds/tax_RDP_final.rds") 

```

## Make phyloseq 

Following taxonomic assignment, both the sequence table and taxonomic table are passed to the Phyloseq R package for further community analysis and visualisation of data. This involves loading in the sample info csv to merge with the sequence and taxonomy tables

```{r create PS, eval = FALSE}
seqtab.nochim <- readRDS("output/rds/seqtab_final.rds")
tax_plus <- readRDS("output/rds/tax_RDP_final.rds") 

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/Sample_info.csv", header=TRUE)
samdf <- samdf[!duplicated(samdf$SampleID),] #Remove duplicate entries for reverse reads

rownames(samdf) <- samdf$SampleID
keep.cols <- c("collection_date", "biome", "target_gene", "feature",
"pool_comp" ,"SampleID","experimental_factor")
samdf <- samdf[rownames(seqtab.nochim), keep.cols]

#Display samDF
head(samdf)

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax_plus), sample_data(samdf),
               otu_table(seqtab.nochim, taxa_are_rows = FALSE))
##save phyloseq object
saveRDS(ps, "output/rds/ps_rdp.rds") 
```


## Output tables of results

```{r output table, eval = FALSE}
ps <- readRDS("output/rds/ps_rdp.rds")

dir.create("output/csv")
dir.create("output/csv/unfiltered/")
dir.create("output/csv/filtered/")
dir.create("output/csv/seperategenes/")

##Define helper functions

#Function to transform data to proportions
proportions = function(x){
  xprop = (x / sum(x))
  return(xprop)
}

##Function to transform data to proportions and set low proportions to zero
filterfun = function(x){
  xprop = (x / sum(x)) #Convert to proportions
  xprop[xprop < (0.00011664)] <- 0 ## remove taxa under this level - Derived from the index switching rate from 100/500/1000 pool run
  return(xprop)
}


##Export raw csv
export <- psmelt(ps)
write.csv(export, file = "output/csv/unfiltered/rawdata.csv")

#Agglomerate all OTU's to Gene level and export proportions - For supplementary table
sum_gene <- transform_sample_counts(ps, fun = proportions)
sum_gene <- summarize_taxa(sum_gene, "Gene", "SampleID")
sum_gene <- spread(sum_gene, key="SampleID", value="totalRA")

write.csv(sum_gene, file = "output/csv/unfiltered/gene_summarized.csv")

#Subset data to Athropoda only & Export CSV
ps1 = subset_taxa(ps, Phylum == "Arthropoda") 
export <- psmelt(ps1)
write.csv(export, file = "output/csv/unfiltered/raw_arthropoda.csv")

#Agglomerate all OTUS and export summary table pre-filtering (for index switching figure)

sum_spp <- summarize_taxa(ps1, "Species", "SampleID")
sum_spp <- spread(sum_spp, key="SampleID", value="totalRA")
write.csv(sum_spp, file = "output/csv/unfiltered/allgene_sppglom_unfiltered_summarized.csv")

sum_gen <- summarize_taxa(ps1, "Genus", "SampleID")
sum_gen <- spread(sum_gen, key="SampleID", value="totalRA")
write.csv(sum_gen, file = "output/csv/unfiltered/allgene_genglom_unfiltered_summarized.csv")

#Convert arthropod data to proportions and apply filter threshold
psFR <- transform_sample_counts(ps1, fun = filterfun)
psFR <- transform_sample_counts(psFR, fun = proportions)
psFR = filter_taxa(psFR, function(x) mean(x) > 0, TRUE) #Drop missing

##Export filtered data
export <- psmelt(psFR)
write.csv(export, file = "output/csv/filtered/allgene_arthropoda_filt.csv")

#Agglomerate all filtered OTUS by species & Genus level taxonomy and export
rm_c1 <-  c("Pool-C1-250","Pool-C2-250","Pool-C3-250","Pool-C4-250","Pool-C5-250")
spp_level <- subset_samples(psFR, sample_names(psFR)!=rm_c1)
spp_level = tax_glom(spp_level, "Species", NArm = FALSE)
sppexport <- psmelt(spp_level)
write.csv(sppexport, file = "output/csv/filtered/allgene_sppglom_filt.csv")

gen_level <- subset_samples(psFR, sample_names(psFR)!=rm_c1)
gen_level = tax_glom(gen_level, "Genus", NArm = FALSE)
genexport <- psmelt(gen_level)
write.csv(genexport, file = "output/csv/filtered/allgene_genglom_filt.csv")

#Agglomerate all filtered OTUS by species level taxonomy, then create summary table and export
sum_spp_filt <- summarize_taxa(psFR, "Species", "SampleID")
sum_spp_filt <- spread(sum_spp_filt, key="SampleID", value="totalRA")
write.csv(sum_spp_filt, file = "output/csv/filtered/allgene_sppglom_filt_summarized.csv")

sum_gen_filt <- summarize_taxa(psFR, "Genus", "SampleID")
sum_gen_filt <- spread(sum_gen_filt, key="SampleID", value="totalRA")
write.csv(sum_gen_filt, file = "output/csv/filtered/allgene_genglom_filt_summarized.csv")
```

#Plotting 


# Add expected abundances for all samples 

As part of the mock community analysis, we wish to determine taxonomic bias by looking at observed vs expected reads. To do this, we load dummy sequence, taxonomy, and sample data tables and create a seperate phyloseq object, which will later be merged

This loads a dummy sequence table, taxonomy table, and sample data table and merges it into the existing phyloseq object
```{r Figure 1 - merged figure}
#get expected abundances

exp_seqtab <- as.matrix(read.csv("sample_data/expected/exp_seqtab.csv",row.names=1, header=TRUE))
exp_taxtab <- as.matrix(read.csv("sample_data/expected/exp_taxtab.csv",row.names=1, header=TRUE))
exp_samdf <- read.csv("sample_data/expected/exp_samdf.csv", header=TRUE)

keep.cols <- c("collection_date", "biome", "target_gene", "feature",
"pool_comp" ,"SampleID","experimental_factor")
rownames(exp_samdf) <- exp_samdf$SampleID
exp_samdf <- exp_samdf[rownames(exp_seqtab), keep.cols]

## Make phyloseq and merge
ps_exp <- phyloseq(tax_table(exp_taxtab), sample_data(exp_samdf),
               otu_table(exp_seqtab, taxa_are_rows = FALSE))


#Figure 1 - Mock communities observed Vs Expected

rm_c1 <-  c("Pool-C1-250","Pool-C2-250","Pool-C3-250","Pool-C4-250","Pool-C5-250")
rm_c1_exp<- c("Pool-C1-250-exp","Pool-C2-250-exp","Pool-C3-250-exp","Pool-C4-250-exp","Pool-C5-250-exp")

#Expected

#Drop Kingdom column so we have 3 genes merged 
tax_table(ps_exp) <- tax_table(ps_exp)[,2:7]
ps_exp <- subset_samples(ps_exp, biome == "Laboratory")
ps_exp <- subset_taxa(ps_exp, Phylum == "Arthropoda")
ps_exp <- subset_samples(ps_exp, sample_names(ps_exp)!=rm_c1_exp)
ps_exp = tax_glom(ps_exp, "Species", NArm = TRUE)

##Subset to mock communities

ps_exp = filter_taxa(ps_exp, function(x) mean(x) > 0, TRUE)
ps_exp <- transform_sample_counts(ps_exp, fun= proportions) # Reset scale to 1 following NArm
df_exp <- psmelt(ps_exp)

#Reorder to pool composition
df_exp$SampleID <- factor(df_exp$SampleID, levels = unique(df_exp$SampleID[order(-df_exp$pool_comp)]))

#Plot horizontal mock communities

pexp <- ggplot(df_exp, aes(x= SampleID, y=Abundance,fill= Genus)) + 
  geom_bar(stat = "identity", position = "stack", color = "NA")  + 
  theme_pubclean() +
    theme(axis.text.x = element_text(angle = -90, hjust = 0),
        plot.title=element_text(hjust = 0.5)) + 
  ggtitle(paste0("Expected")) + 
  scale_fill_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77")) +
  coord_flip()


## All genes merged
psmock <- psFR
#Drop Kingdom column so we have 3 genes merged 
tax_table(psmock) <- tax_table(psmock)[,2:7]
psmock <- subset_samples(psmock, biome == "Laboratory")
psmock <- subset_taxa(psmock, Phylum == "Arthropoda")
rm_c1 <-  c("Pool-C1-250","Pool-C2-250","Pool-C3-250","Pool-C4-250","Pool-C5-250")
psmock <- subset_samples(psmock, sample_names(psmock)!=rm_c1)
psmock = tax_glom(psmock, "Species", NArm = TRUE)

##Subset to mock communities

psmock = filter_taxa(psmock, function(x) mean(x) > 0, TRUE)
psmock <- transform_sample_counts(psmock, fun= proportions) # Reset scale to 1 following NArm
df_mock <- psmelt(psmock)

#Reorder to pool composition
df_mock$SampleID <- factor(df_mock$SampleID, levels = unique(df_mock$SampleID[order(-df_mock$pool_comp)]))

#Plot horizontal mock communities

pmock <- ggplot(df_mock, aes(x= SampleID, y=Abundance,fill= Genus)) + 
  geom_bar(stat = "identity", position = "stack", color = "NA")  + 
  theme_pubclean() +
    theme(axis.text.x = element_text(angle = -90, hjust = 0),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        plot.title=element_text(hjust = 0.5),
        legend.position = "none") + 
  ggtitle(paste0("3 Genes")) + 
  scale_fill_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77")) +
  coord_flip()


#COI
ps_coi <- subset_taxa(psFR, Gene == "COI-Eukaryota")
ps_coi <- subset_taxa(ps_coi, Phylum == "Arthropoda")
ps_coi = subset_samples(ps_coi, biome == "Laboratory")
ps_coi = tax_glom(ps_coi, "Species", NArm = TRUE)
tax_table(ps_coi) <- tax_table(ps_coi)[,2:7]

##Transform data to proportions and set low proportions to zero
psra_coi <- transform_sample_counts(ps_coi, fun = proportions)
psra_coi = filter_taxa(psra_coi, function(x) mean(x) > 0, TRUE)

#Remove combinatorial indexed samples
psra_coi <- subset_samples(psra_coi, sample_names(psra_coi)!=rm_c1)
psra_coi <- subset_samples(psra_coi, sample_names(psmock)!=rm_c1_exp)
df_coi <- psmelt(psra_coi)

#Reorder to pool composition
df_coi$SampleID <- factor(df_coi$SampleID, levels = unique(df_coi$SampleID[order(-df_coi$pool_comp)]))

#Plot COI mock communities

pcoi <- ggplot(df_coi, aes(x= SampleID, y=Abundance,fill= Genus)) + 
  geom_bar(stat = "identity", position = "stack", color = "NA")  + 
  theme_pubclean() +
    theme(axis.text.x = element_text(angle = -90, hjust = 0),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        plot.title=element_text(hjust = 0.5),
        legend.position = "none") + 
  ggtitle(paste0("COI")) + 
  scale_fill_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77")) +
  coord_flip()


#18S
ps_18s <- subset_taxa(psFR, Gene == "18s-Eukaryota")
ps_18s <- subset_taxa(ps_18s, Phylum == "Arthropoda")
ps_18s = subset_samples(ps_18s, biome == "Laboratory")
ps_18s = tax_glom(ps_18s, "Species", NArm = TRUE)
tax_table(ps_18s) <- tax_table(ps_18s)[,2:7]

##Transform data to proportions and set low proportions to zero
psra_18s <- transform_sample_counts(ps_18s, fun = proportions)
psra_18s = filter_taxa(psra_18s, function(x) mean(x) > 0, TRUE)

#Remove combinatorial indexed samples
psra_18s <- subset_samples(psra_18s, sample_names(psra_18s)!=rm_c1)
psra_18s <- subset_samples(psra_18s, sample_names(psmock)!=rm_c1_exp)
df_18s <- psmelt(psra_18s)

#Reorder to pool composition
df_18s$SampleID <- factor(df_18s$SampleID, levels = unique(df_18s$SampleID[order(-df_18s$pool_comp)]))

#Plot 18S mock communities

p18s <- ggplot(df_18s, aes(x= SampleID, y=Abundance,fill= Genus)) + 
  geom_bar(stat = "identity", position = "stack", color = "NA")  + 
  theme_pubclean() +
    theme(axis.text.x = element_text(angle = -90, hjust = 0),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        plot.title=element_text(hjust = 0.5),
        legend.position = "none") + 
  ggtitle(paste0("18S")) + 
  scale_fill_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77")) +
  coord_flip()


#12s
ps_12s <- subset_taxa(psFR, Gene == "12S-Eukaryota")
ps_12s <- subset_taxa(ps_12s, Phylum == "Arthropoda")
ps_12s = subset_samples(ps_12s, biome == "Laboratory")
ps_12s = tax_glom(ps_12s, "Species", NArm = TRUE)
tax_table(ps_12s) <- tax_table(ps_12s)[,2:7]

##Transform data to proportions and set low proportions to zero
psra_12s <- transform_sample_counts(ps_12s, fun = proportions)
psra_12s = filter_taxa(psra_12s, function(x) mean(x) > 0, TRUE)

#Remove combinatorial indexed samples
psra_12s <- subset_samples(psra_12s, sample_names(psra_12s)!=rm_c1)
psra_12s <- subset_samples(psra_12s, sample_names(psmock)!=rm_c1_exp)
df_12s <- psmelt(psra_12s)

#Reorder to pool composition
df_12s$SampleID <- factor(df_12s$SampleID, levels = unique(df_12s$SampleID[order(-df_12s$pool_comp)]))

#Plot 12s mock communities

p12s <- ggplot(df_12s, aes(x= SampleID, y=Abundance,fill= Genus)) + 
  geom_bar(stat = "identity", position = "stack", color = "NA")  + 
  theme_pubclean() +
    theme(axis.text.x = element_text(angle = -90, hjust = 0),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        plot.title=element_text(hjust = 0.5),
        legend.position = "none") + 
  ggtitle(paste0("12s")) + 
  scale_fill_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77")) +
  coord_flip()

#Use patchwork to stich together
Fig1 <- pexp + pmock + pcoi + p18s + p12s + plot_layout(ncol = 5)

```

# Figure 2: Detection table
```{r figure 2}
#Problem named taxa - Need to gsub names
#Rhopalosiphum insertum/oxyacanthae <- Rhopalosiphum insertum
#Rhopalosiphum rufiabdominale/rufiabdominalis <- Rhopalosiphum rufiabdominale
#Lonchoptera bifurcata/uniseta
#Lipaphis erysimi/pseudobrassicae

positions = c('Pool-01-100', 'Pool-02-100', 'Pool-03-100', 'Pool-04-100', 'Pool-05-100', 'Pool-06-500', 'Pool-07-500', 'Pool-08-500', 'Pool-09-500', 'Pool-10-500', 'Pool-11-1000', 'Pool-12-1000', 'Pool-13-1000', 'Pool-14-1000', 'Pool-15-1000', 'Pool-U1-250', 'Pool-U2-250', 'Pool-U3-250', 'Pool-U4-250', 'Pool-U5-250', 'Trap-01', 'Trap-02', 'Trap-03', 'Trap-04', 'Trap-05', 'Trap-06', 'Trap-07', 'Trap-08', 'Trap-09', 'Trap-10')

#Drop Kingdom column so we have 3 genes merged 
psglom <- psFR
tax_table(psglom) <- tax_table(psglom)[,2:7]
psglom = tax_glom(psglom, "Species", NArm = TRUE)
psglom <- transform_sample_counts(psglom, fun= proportions) # Reset scale to 1 following NArm
psglom = filter_taxa(psglom, function(x) mean(x) > 0, TRUE)

p4 <- plot_heatmap(psglom, "NMDS", "bray", taxa.label="Species", taxa.order="Family", na.value="white") +
  theme_pubr()  +
  scale_x_discrete(limits = positions) +
  theme(axis.text.x = element_text(angle=60, hjust=1),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        legend.position="none") +
  scale_fill_viridis(trans=log_trans(10),begin=0, na.value="white") 

  
#Plot which genes taxa was detected with
mdt = fast_melt(psFR)
  summarydt = mdt[, list(totalRA = sum(RelativeAbundance)),
                  by = c("Gene","Order","Family", "Genus","Species", "SampleID", "taxaID")]
  summarydt <- summarydt[!is.na(summarydt$Species)]
  summarydt$totalRA[summarydt$totalRA > 0] <- 1
  
#Get taxanomic orders similar to heatmap
  rankcol = which(rank_names(psglom) %in% "Family")
  taxmat = as(tax_table(psglom)[, 1:rankcol], "matrix")
  taxa.order = apply(taxmat, 1, paste, sep = "", collapse = "")
  names(taxa.order) <- taxa_names(psglom)
  taxa.order = as.tibble(names(sort(taxa.order, na.last = TRUE)))
  colnames(taxa.order) <- "taxaID"
  taxa.order$seq <- seq(1:nrow(taxa.order))
  reorder <- full_join(taxa.order,summarydt,by="taxaID") 

  reorder$Species <- factor(reorder$Species, levels = unique(reorder$Species[order(reorder$seq)]))

p5 <- ggplot(reorder, aes(Gene, Species)) + geom_point(aes(colour = Gene),size=3) + theme(legend.position="none") + coord_fixed(ratio=.5) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=60, hjust=1),
        axis.title.x=element_blank(), 
        axis.title.y=element_blank()) + 
  theme(legend.position="none")


#Plot higher order ranks
pname <- ggplot(reorder, aes(x=c(1), Species) ) + geom_tile(aes(fill=reorder$Order),alpha=0.5)+ geom_text(label=reorder$Order) + theme_void() + theme(legend.position="none")


Fig2 <- pname + p5 + p4 + plot_layout(ncol = 3, widths=c(1,2,3))


```


Index switching figures
```{r}
##CREATE ALL COMBINATIONS

#Read in original sample sheet
SampleSheet <- read_csv("demulti/SampleSheet_Run6.csv",skip=20)

I7_Index_ID <- SampleSheet$index
I5_Index_ID <- SampleSheet$index2

combos <- unique(expand.grid(I7_Index_ID, I5_Index_ID))
combos$name <- paste0(combos$Var1,"_",combos$Var2)


#exclude real combinations

real <- as.data.frame(cbind(I7_Index_ID,I5_Index_ID,SampleSheet$Sample_ID))
real$name <- paste0(real$I7_Index_ID,"_",real$I5_Index_ID)

unexpected <- combos[!combos$name %in% real$name, ]

#write.csv(unexpected,file="demulti/Run6_unexpected.csv")

##READ DEMULTIPLEXED ALL

demulti <- read.table("demulti/readcount_mock.txt")

unique_sample <- demulti$V1 %>%
  str_replace_all("-","_") %>%
  str_split_fixed("_", n=3) 


unique_sample <- paste0(unique_sample[,1],"_",unique_sample[,2])

demulti$V1 <- unique_sample

colnames(demulti) <- c("sample","reads","unique.reads","unique.perc","topseq","topseq.freq","topseq.perc")

demulti <- demulti %>%
  distinct(sample, .keep_all=TRUE)

#demulti$sample[1:10] <- paste0(I7_Index_ID,"_",I5_Index_ID)

colnames(real)[3] <- "sample"

demulti <- left_join(demulti,real,by="sample")

demulti$name[is.na(demulti$name)] <- demulti$sample[is.na(demulti$name)]

##Summary of index switching rate
exp_rate <- demulti %>% 
  filter(str_detect(sample,paste(c("Pool", "Trap"),collapse = '|')))
obs_rate <- demulti %>% 
  filter(!str_detect(sample,paste(c("Pool", "Trap"),collapse = '|')))

switch_rate <- (sum(obs_rate$reads)/sum(exp_rate$reads)) *100

##plot index switching

plot <- demulti %>%
  separate(name,c("i7","i5"),"_")%>%
  select(i7,i5,reads)

searchi5 <- exp_rate$I5_Index_ID
searchi7 <-exp_rate$I7_Index_ID
replacement <- exp_rate$sample



i=1
for (i in 1:length(replacement))
{
  plot$i7 <- as.character(plot$i7) %>%
  str_replace(pattern= as.character(searchi7[i]), replacement=paste0(replacement[i],"-",as.character(searchi7[i]))) 
  
  plot$i5 <- as.character(plot$i5) %>%
    str_replace(pattern= as.character(searchi5[i]), replacement=paste0(replacement[i],"-",as.character(searchi5[i]))) 
}
orderi7 <- c("Pool_1-GACGAGAT", "Pool_2-TAGTGGCA",  "Pool_3-CATTAACG", "Pool_4-TCGTTGAA", "Pool_5-TAGTACGC", "Pool_6-TTCACCGT",
             "Pool_7-AGGACAGT", "Pool_8-AATCGTGG",  "Pool_9-TGAATGCC",  "Pool_10-GTGCAATG", "Pool_11-AGTGGCAT",  "Pool_12-AGTCTACC",
             "Pool_13-ATCGGTAG",  "Pool_14-CGTATGAT",  "Pool_15-CTGTCGTA")

orderi5 <- c("Pool_1-GACTTCGT", "Pool_2-AATCTCGT",  "Pool_3-TTGCCACT", "Pool_4-GCGTTAAT", "Pool_5-CTTCAACG", "Pool_6-AGCGTACT",
             "Pool_7-TACGGTGA", "Pool_8-AACTGTCC",  "Pool_9-GACTGATA",  "Pool_10-ACATCTGC", "Pool_11-ACGTTAGG",  "Pool_12-CACTAGAC",
             "Pool_13-TGGCATTC",  "Pool_14-ACATTGCA",  "Pool_15-TATGCCAC")


plot$i7 <- factor(plot$i7, levels = orderi7)
plot$i5 <- factor(plot$i5 , levels = rev(orderi5))

Fig3 <- ggplot(data = plot, aes(x = i7, y = i5), stat="identity") +
  geom_tile(aes(fill = reads),alpha=0.9)  + scale_fill_viridis(name = "reads", begin=0.1,trans = "log10")  + geom_text(label=demulti$reads) + 
  theme(axis.text.x = element_text(angle=90, hjust=1), plot.title=element_text(hjust = 0.5), plot.subtitle =element_text(hjust = 0.5), legend.position = "none") +
  labs(title= "100-500-1000 Pool Samples", subtitle = paste0("Index switch rate for the run: ", sprintf("%1.2f%%", switch_rate)))


```


```{r supplementary - Index switching}

##Get edit distance for used combinations

#Set colour table
colorTable <- designer.colors(8, c( "red","yellow", "white"),
                              x = c(0, 5, 8) / 140)
col_order <- SampleSheet$Sample_Name
# Hamming i7

  hami7 <- as.tibble(stringdistmatrix(SampleSheet$index, SampleSheet$index, "hamming"))
  
  #colnames(hami7) <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index)
  #hami7$row <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index)
  colnames(hami7) <- SampleSheet$Sample_Name
  hami7$row <- SampleSheet$Sample_Name
  hami7 <- hami7 %>% 
    gather(key="col","value",-row)
  

  hami7$row <- factor(hami7$row, levels = col_order)
  hami7$col <- factor(hami7$col, levels = rev(col_order))
  
phami7 <- ggplot(data = hami7, aes(x = row, y = col), stat="identity")  + 
  geom_tile(data = hami7,aes(fill = as.factor(value))) + 
    scale_fill_manual(values = colorTable) + 
    geom_text(label=hami7$value)   +  
  theme(axis.text.x = element_text(angle=90, hjust=1)) + theme(plot.title=element_text(hjust = 0.5), plot.subtitle =element_text(hjust = 0.5), legend.position = "none", axis.title.x=element_blank(), axis.title.y=element_blank()) +
  labs(title= "Hamming distance for i7 index")  


# Hamming i5

hami5 <- as.tibble(stringdistmatrix(SampleSheet$index2, SampleSheet$index2, "hamming"))

#colnames(hami5) <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index2)
#hami5$row <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index2)
colnames(hami5) <- SampleSheet$Sample_Name
hami5$row <- SampleSheet$Sample_Name

hami5 <- hami5 %>% 
  gather(key="col","value",-row)


hami5$row <- factor(hami5$row, levels = col_order)
hami5$col <- factor(hami5$col, levels = rev(col_order))

phami5 <- ggplot(data = hami5, aes(x = row, y = col), stat="identity")  + 
  geom_tile(data = hami5,aes(fill = as.factor(value))) + 
  scale_fill_manual(values = colorTable) + 
  geom_text(label=hami5$value)   +  
  theme(axis.text.x = element_text(angle=90, hjust=1)) + theme(plot.title=element_text(hjust = 0.5), plot.subtitle =element_text(hjust = 0.5), legend.position = "none", axis.title.x=element_blank(), axis.title.y=element_blank()) +
  labs(title= "Hamming distance for i5 index")  

# Levenshtein i7

lvi7 <- as.tibble(stringdistmatrix(SampleSheet$index, SampleSheet$index, "lv"))

#colnames(lvi7) <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index)
#lvi7$row <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index)
colnames(lvi7) <- SampleSheet$Sample_Name
lvi7$row <- SampleSheet$Sample_Name
lvi7 <- lvi7 %>% 
  gather(key="col","value",-row)


lvi7$row <- factor(lvi7$row, levels = col_order)
lvi7$col <- factor(lvi7$col, levels = rev(col_order))

plvi7 <- ggplot(data = lvi7, aes(x = row, y = col), stat="identity")  + 
  geom_tile(data = lvi7,aes(fill = as.factor(value))) + 
  scale_fill_manual(values = colorTable) + 
  geom_text(label=lvi7$value)   +  
  theme(axis.text.x = element_text(angle=90, hjust=1)) + theme(plot.title=element_text(hjust = 0.5), plot.subtitle =element_text(hjust = 0.5), legend.position = "none", axis.title.x=element_blank(), axis.title.y=element_blank()) +
  labs(title= "Levenshtein distance for i7 index")  


# Levenshtein i5

lvi5 <- as.tibble(stringdistmatrix(SampleSheet$index2, SampleSheet$index2, "lv"))

#colnames(lvi5) <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index2)
#lvi5$row <- paste0(SampleSheet$Sample_Name, " - ", SampleSheet$index2)
colnames(lvi5) <- SampleSheet$Sample_Name
lvi5$row <- SampleSheet$Sample_Name

lvi5 <- lvi5 %>% 
  gather(key="col","value",-row)

lvi5$row <- factor(lvi5$row, levels = col_order)
lvi5$col <- factor(lvi5$col, levels = rev(col_order))

plvi5 <- ggplot(data = lvi5, aes(x = row, y = col), stat="identity")  + 
  geom_tile(data = lvi5,aes(fill = as.factor(value))) + 
  scale_fill_manual(values = colorTable) + 
  geom_text(label=lvi5$value)   +  
  theme(axis.text.x = element_text(angle=90, hjust=1)) + theme(plot.title=element_text(hjust = 0.5), plot.subtitle =element_text(hjust = 0.5), legend.position = "none", axis.title.x=element_blank(), axis.title.y=element_blank()) +
  labs(title= "Levenshtein distance for i5 index")  



#Create multiplot
phami7 + phami5 + plvi7 + plvi5 + plot_layout(ncol = 2)
  


##i7 colour balancing

  spliti7 <- str_split(I7_Index_ID, "", n = Inf, simplify = FALSE)
  spliti7 <- as.tibble(t(data.frame(spliti7)))
  colnames(spliti7) <- c(1:8)
  
  spliti7$Name <- I7_Index_ID
  
  spliti7 <- spliti7 %>% 
    gather(Pos,Base,-Name)
  
  #Plots
  
  pspliti7 <-ggplot(data=spliti7, aes(x=Pos, y=1, fill=Base))+
    geom_bar(stat="identity", position=position_fill()) + theme_pubclean()  +   scale_fill_manual(values= c("Red","dodgerblue",  "Yellow", "lawngreen") ) + 
    ggtitle("Colour balance for i7 read") + theme(plot.title=element_text(hjust = 0.5), axis.title.y=element_blank()) +
    xlab("Position within index read") + ylab("Base Composition")
  
#i5 Colour balancing
  spliti5 <- str_split(I5_Index_ID, "", n = Inf, simplify = FALSE)
  spliti5 <- as.tibble(t(data.frame(spliti5)))
  colnames(spliti5) <- c(1:8)
  
  spliti5$Name <- I7_Index_ID
  
  spliti5 <- spliti5 %>% 
    gather(Pos,Base,-Name)
  
  #Plots
  
  pspliti5 <-ggplot(data=spliti5, aes(x=Pos, y=1, fill=Base))+
    geom_bar(stat="identity", position=position_fill()) + theme_pubclean()  +   scale_fill_manual(values= c("Red","dodgerblue",  "Yellow", "lawngreen") ) + 
    ggtitle("Colour balance for i5 read") + theme(plot.title=element_text(hjust = 0.5), axis.title.y=element_blank()) +
    xlab("Position within index read") + ylab("Base Composition")

  #Create multiplot
phami7 + phami5 + plvi7 + plvi5 + pspliti7 + pspliti5 + plot_layout(ncol = 2, nrow=3)


##Plot barcode plates

plates <- read_csv("demulti/qbarcodeplatescsv.csv")


plates$index <- factor(plates$index , levels=(unique(plates$index))[order(plates$Column)])
plates$index2 <- factor(plates$index2 , levels=(unique(plates$index2))[order(plates$Row)])

gplate <-ggplot(data=plates, aes(x=index, y=reorder(index2, desc(index2))))  +
  geom_tile(aes(fill=index2),alpha=0.5,colour="black") +
  geom_tile(aes(fill=index),alpha=0.5,colour="black") +
  geom_tile(aes(fill=Used),alpha=1,colour="black") +
  geom_text(aes(label = paste0(plates$Row,plates$Column)),show.legend = FALSE) +  # adding text for first course
    theme(plot.title=element_text(hjust = 0.5), plot.subtitle =element_text(hjust = 0.5), legend.position = "none",axis.text.x = element_text(angle=90, hjust=1)) +
  labs(title= "mpxPE Barcode plate layouts") + scale_fill_viridis(name = "reads", discrete = TRUE) +
  scale_x_discrete(breaks=(plates$index)[order(plates$Column)]) +
  scale_y_discrete(breaks=(plates$index2)) +  xlab("i7 Index") + ylab("i5 Index") +
  facet_wrap(~Plate, nrow=2,ncol=2, drop=TRUE,scales="free")

gplate +  facet_grid(~Plate,scales="free")
```




## Supplementary Figures - Plot each gene seperately

```{r Seperate genes}

positions = c('Pool-01-100', 'Pool-02-100', 'Pool-03-100', 'Pool-04-100', 'Pool-05-100', 'Pool-06-500', 'Pool-07-500', 'Pool-08-500', 'Pool-09-500', 'Pool-10-500', 'Pool-11-1000', 'Pool-12-1000', 'Pool-13-1000', 'Pool-14-1000', 'Pool-15-1000', 'Pool-U1-250', 'Pool-U2-250', 'Pool-U3-250', 'Pool-U4-250', 'Pool-U5-250', 'Trap-01', 'Trap-02', 'Trap-03', 'Trap-04', 'Trap-05', 'Trap-06', 'Trap-07', 'Trap-08', 'Trap-09', 'Trap-10')

genes <- unique(psmelt(ps) %>% select(Gene))
genes <- as.vector(genes$Gene)
genes <- genes[!is.na(genes)]

for (i in seq(along=genes)){
print(genes[i])
ps_gene = subset_taxa(psFR, Gene == genes[i])
ps_gene = subset_taxa(ps_gene, Phylum == "Arthropoda")

ps_genexp <- merge_phyloseq(ps_gene, ps_exp)
tax_table(ps_genexp) <- tax_table(ps_genexp)[,2:7]

#Summary export
summary <-  subset_samples(ps_genexp, experimental_factor == "O")
sp_summary <- summarize_taxa(summary, "Species", "SampleID")
sp_summary <- spread(sp_summary, key="SampleID", value="totalRA")
write.csv(sp_summary, file = paste0("output/csv/seperategenes/",genes[i],"_sppglom_filt_summarized.csv"))

gen_summary <- summarize_taxa(summary, "Genus", "SampleID")
gen_summary <- spread(gen_summary, key="SampleID", value="totalRA")
write.csv(gen_summary, file = paste0("output/csv/seperategenes/",genes[i],"_genglom_filt_summarized.csv"))

##Transform data to proportions and set low proportions to zero - NEEDED TO REMOVE INDEX SWITCHING

psra_gene <- transform_sample_counts(ps_genexp, fun = proportions)
##Remove zero counts
psra_gene = filter_taxa(psra_gene, function(x) mean(x) > 0, TRUE) #Used to be 1e-6

##Subset to mock communities
psmock = subset_samples(psra_gene, biome == "Laboratory")
psmock = filter_taxa(psmock, function(x) mean(x) > 0, TRUE)
rm_c1 <-  c("Pool-C1-250","Pool-C2-250","Pool-C3-250","Pool-C4-250","Pool-C5-250")
psmock <- subset_samples(psmock, sample_names(psmock)!=rm_c1)
rm_c1_exp<- c("Pool-C1-250-exp","Pool-C2-250-exp","Pool-C3-250-exp","Pool-C4-250-exp","Pool-C5-250-exp")
psmock <- subset_samples(psmock, sample_names(psmock)!=rm_c1_exp)
psmock = tax_glom(psmock, "Species", NArm = TRUE)
psmock <- transform_sample_counts(psmock, fun= proportions) # Reset scale to 1 following NArm
mdf <- psmelt(psmock)


#Reorder to pool composition
mdf$SampleID <- factor(mdf$SampleID, levels = unique(mdf$SampleID[order(-mdf$pool_comp)]))

#Plot horizontal mock communities

p <- ggplot(mdf, aes(x= SampleID, y=Abundance,fill= Genus))
p = p + geom_bar(stat = "identity", position = "stack", color = "NA")  
p = p + theme(axis.text.x = element_text(angle = -90, hjust = 0))
p = p + ggtitle(paste0("Relative abundance of taxa for all genes in mock communities"))
p = p + xlab("Mock Community") 
p = p + scale_fill_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77"))
p = p + theme_pubclean() 
p1 =  p + facet_wrap(~experimental_factor, drop=TRUE, scales="free")  + coord_flip() #+ theme(axis.text.y = element_blank(), axis.ticks.y=element_blank())

#plot obs/exp seperated 2 rows
p2 = p + facet_wrap(~experimental_factor, nrow=2,ncol=1,drop=TRUE, scales="free") + coord_flip() 

#Plot Heatmap
psreal_gene = subset_samples(psra_gene, experimental_factor != "Exp")
psreal_gene <- subset_samples(psreal_gene, sample_names(psreal_gene)!=rm_c1)

psglom = tax_glom(psreal_gene, "Species", NArm = TRUE)
p3 <- plot_heatmap(psglom, "NMDS", "bray", taxa.label="Species", title= paste0(genes[i]," Heatmap Species level"), taxa.order="Family") + theme_pubr()  + scale_x_discrete(limits = positions) + theme(axis.text.x = element_text(angle=60, hjust=1), axis.title.x=element_blank(), axis.title.y=element_blank(), legend.position="none") + scale_fill_viridis(trans=log_trans(10), na.value="grey10") 

#Plot correlations

##Calculate observed vs expected
psgen = tax_glom(psmock, "Genus", NArm = TRUE)
psgen <- transform_sample_counts(psgen, fun= proportions) # Reset scale to 1 following NArm
psgen <- psmelt(psgen)

mock_exp <- psgen %>%
  filter(experimental_factor=="Exp") %>%
  subset(select=c("Abundance","Sample","Genus"))
mock_exp$Sample <-str_remove(mock_exp$Sample,pattern="-exp")
colnames(mock_exp) <- c("Expected","Sample","Genus")

mock_obs <- psgen %>%
  filter(experimental_factor=="O") %>%
  subset(select=c("Abundance","Sample","Genus"))
colnames(mock_obs) <- c("Observed","Sample","Genus")

expobs <- left_join(mock_exp,mock_obs, by=c("Sample","Genus")) %>%
  filter(Observed>0)

g <- ggplot(expobs,aes(x=Expected,y=Observed)) + geom_point(aes(colour=Genus)) + geom_abline(slope=1, intercept = 0) +
  geom_segment(aes(xend = Expected, yend = Observed)) +
  stat_cor(aes(color = Genus), label.x = 0.1)  + xlim(0,1) + ylim(0,1) + scale_colour_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77")) + theme_pubr() + theme(legend.position = "none") 

##Get differences 
expobs$bias <- expobs$Observed - expobs$Expected 

g2 <- ggplot(expobs,aes(x=Genus,y=bias)) + geom_bar(aes(fill=Genus),stat = "summary", fun.y = "mean") + geom_abline(slope=0, intercept = 0) + scale_fill_manual(values=c("#0c4687","#ae0707","#fa6e24","#3a9e82","#95cf77")) + theme_pubr() #+ coord_flip()


pdf(file= paste0("output/figs/",genes[i],"_plots.pdf"), paper="a4")
plot(p1)
plot(g)
plot(g2)
plot(p3)
dev.off()
}
```
